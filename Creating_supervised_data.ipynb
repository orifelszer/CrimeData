{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Required Libraries"
      ],
      "metadata": {
        "id": "ERjhbz2oDrhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "iY23eswYQBHB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and Importing Preprocessing Function"
      ],
      "metadata": {
        "id": "lqay1_n1D0P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O Prepare_supervised_data_functions.py \"https://raw.githubusercontent.com/orifelszer/CrimeData/refs/heads/main/Prepare_supervised_data_functions.py\"\n",
        "from Prepare_supervised_data_functions import Preprocessing"
      ],
      "metadata": {
        "id": "y_NbyWeMxuYY",
        "outputId": "73d44129-3639-41e4-d14f-8435edea657a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-11 13:28:09--  https://raw.githubusercontent.com/orifelszer/CrimeData/refs/heads/main/Prepare_supervised_data_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8311 (8.1K) [text/plain]\n",
            "Saving to: ‘Prepare_supervised_data_functions.py’\n",
            "\n",
            "\r          Prepare_s   0%[                    ]       0  --.-KB/s               \rPrepare_supervised_ 100%[===================>]   8.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-11 13:28:09 (60.3 MB/s) - ‘Prepare_supervised_data_functions.py’ saved [8311/8311]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Paths for Crime Datasets (2019–2024)\n"
      ],
      "metadata": {
        "id": "HH7ESwFcOeWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Downloading and Extracting Crime Data Files ===\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "!git clone https://github.com/orifelszer/CrimeData.git\n",
        "\n",
        "zip_folder = 'CrimeData'\n",
        "# Extracting only ZIP files for the years 2019 to 2024\n",
        "zip_files = [f for f in os.listdir(zip_folder) if f.startswith('crimes') and any(str(year) in f for year in range(2019, 2025))]\n",
        "\n",
        "# Unzipping files and saving the new folder paths\n",
        "extracted_folders = []\n",
        "\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(zip_folder, zip_file)\n",
        "    extract_path = os.path.join(zip_folder, zip_file.replace('.zip', ''))\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    extracted_folders.append(extract_path)\n",
        "    print(f\"Extracted: {zip_file} -> {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNxHCYGhOb6y",
        "outputId": "59310b36-1b1b-4fbd-99f0-a995e52a3103"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CrimeData'...\n",
            "remote: Enumerating objects: 712, done.\u001b[K\n",
            "remote: Counting objects: 100% (235/235), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 712 (delta 182), reused 96 (delta 96), pack-reused 477 (from 3)\u001b[K\n",
            "Receiving objects: 100% (712/712), 228.16 MiB | 31.44 MiB/s, done.\n",
            "Resolving deltas: 100% (365/365), done.\n",
            "Extracted: crimes2020.zip -> CrimeData/crimes2020\n",
            "Extracted: crimes2023.zip -> CrimeData/crimes2023\n",
            "Extracted: crimes2024.zip -> CrimeData/crimes2024\n",
            "Extracted: crimes2019.zip -> CrimeData/crimes2019\n",
            "Extracted: crimes2021.zip -> CrimeData/crimes2021\n",
            "Extracted: crimes2022.zip -> CrimeData/crimes2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Crime Data into Pandas DataFrames"
      ],
      "metadata": {
        "id": "FdI-ivysOl8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = []\n",
        "for folder in extracted_folders:\n",
        "    csv_files += glob.glob(os.path.join(folder, \"*.csv\"))\n",
        "\n",
        "dataframes = {f\"Crimes_{file[-8:-4]}\": pd.read_csv(file) for file in csv_files}\n",
        "combined_data = pd.concat(dataframes.values(), axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "sLByLu1aOi9B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Invalid Rows"
      ],
      "metadata": {
        "id": "P9omt-56FsRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rows where 'StatisticGroupKod' equals -1 are removed, as -1 is a typing mistake in the data.\n",
        "combined_data = combined_data[combined_data['StatisticGroupKod'] != -1]"
      ],
      "metadata": {
        "id": "cItUkZWDOtLo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Features and Target Variable"
      ],
      "metadata": {
        "id": "h7kEDbvWGIlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = combined_data.drop(['StatisticGroup', 'StatisticGroupKod'], axis=1)\n",
        "target = combined_data['StatisticGroup']\n",
        "\n",
        "# Splitting Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features,\n",
        "    target,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=target\n",
        "    )"
      ],
      "metadata": {
        "id": "I4UsQaPfPAh7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Preprocessing Function"
      ],
      "metadata": {
        "id": "Yv0LxaSIGWLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cleaned, train_mappings, scaler, label_encoders = Preprocessing(X_train, fit_scaler=True)\n",
        "X_test_cleaned, _, _, _ = Preprocessing(X_test, train_mappings=train_mappings, scaler=scaler)"
      ],
      "metadata": {
        "id": "TQBq583ZPDMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9e0d3e-55bb-40bf-dfa2-e7d2161432b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Prepare_supervised_data_functions.py:65: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  lambda x: x.fillna(fill_statistic_area_random(x)))\n",
            "/content/Prepare_supervised_data_functions.py:65: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  lambda x: x.fillna(fill_statistic_area_random(x)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retaining Relevant Columns and Aligning Datasets"
      ],
      "metadata": {
        "id": "A8vwP2H6HE9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retaining only columns where the sum of values in the training set is significant (at least 10)\n",
        "columns_to_keep = [col for col in X_train_cleaned.columns if X_train_cleaned[col].sum() >= 10]\n",
        "X_train_cleaned = X_train_cleaned[columns_to_keep]\n",
        "\n",
        "# Ensuring the test set includes the same columns as the training set\n",
        "for col in columns_to_keep:\n",
        "    if col not in X_test_cleaned.columns:\n",
        "        X_test_cleaned[col] = 0\n",
        "X_test_cleaned = X_test_cleaned[X_train_cleaned.columns]"
      ],
      "metadata": {
        "id": "kMIYcWlpPGNW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aligning Target Variables with Cleaned Datasets"
      ],
      "metadata": {
        "id": "C_gf3Mo1HeEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.loc[X_train_cleaned.index]\n",
        "y_test = y_test.loc[X_test_cleaned.index]"
      ],
      "metadata": {
        "id": "tEuKxKWSPJzw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Target Variable"
      ],
      "metadata": {
        "id": "Wca9Cq3DHjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "Qrdfjkscl0ND"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving Cleaned Datasets and Encoded Targets as CSV Files"
      ],
      "metadata": {
        "id": "azVPjzgsIQiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cleaned.to_csv('X_train_supervised.csv', index=False)\n",
        "X_test_cleaned.to_csv('X_test_supervised.csv', index=False)\n",
        "pd.DataFrame(y_train_encoded).to_csv('y_train_supervised.csv', index=False, header=['target'])\n",
        "pd.DataFrame(y_test_encoded).to_csv('y_test_supervised.csv', index=False, header=['target'])"
      ],
      "metadata": {
        "id": "u2WiIdnETJFd"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}