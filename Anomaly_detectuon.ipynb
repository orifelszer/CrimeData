{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [

      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "id": "-7mcT73id8cE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # לעבודה עם נתונים טבלאיים\n",
        "import matplotlib.pyplot as plt  # להצגת גרפים\n",

      ]
    },
    {
      "cell_type": "code",
      "source": [

        "\n",
        "# הורדת הנתונים מה-GitHub\n",
        "!git clone https://github.com/orifelszer/CrimeData.git\n",
        "\n",
        "# הגדרת התיקייה לאחר ההורדה\n",
        "zip_folder = 'CrimeData'\n",
        "\n",
        "# הגדרת נתיבים ישירים לשני הקבצים\n",
        "zip_files = [\n",
        "    os.path.join(zip_folder, 'Clean_data_unsupervised_part1.zip'),\n",
        "    os.path.join(zip_folder, 'Clean_data_unsupervised_part2.zip')\n",
        "]\n",
        "\n",
        "# רשימה לשמירת נתיבי הקבצים שנפרסו\n",
        "extracted_folders = []\n",
        "\n",
        "# פריסת קבצי ה-ZIP\n",
        "for zip_file in zip_files:\n",
        "    extract_path = zip_file.replace('.zip', '')  # יצירת שם תיקייה לפי שם הקובץ\n",
        "\n",
        "    # בדיקה אם הקובץ קיים\n",
        "    if os.path.exists(zip_file):\n",
        "        # בדיקה אם התיקייה כבר נפרסה\n",
        "        if not os.path.exists(extract_path):\n",
        "            with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "            print(f\"Extracted: {zip_file} -> {extract_path}\")\n",
        "        else:\n",
        "            print(f\"Skipped: {zip_file} (Already extracted)\")\n",
        "    else:\n",
        "        print(f\"File not found: {zip_file}\")\n",
        "\n",
        "    extracted_folders.append(extract_path)\n",
        "\n",
        "# איחוד קבצי CSV שפורסו\n",
        "dataframes = []\n",
        "\n",
        "for folder in extracted_folders:\n",
        "    for file_name in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, file_name)\n",
        "        if file_name.endswith('.csv'):\n",
        "            df_temp = pd.read_csv(file_path)\n",
        "            dataframes.append(df_temp)\n",
        "\n",
        "# איחוד כל הנתונים למסגרת נתונים אחת\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# הצגת מסגרת הנתונים המאוחדת\n",
        "print(f\"Combined dataset contains {combined_df.shape[0]} rows and {combined_df.shape[1]} columns.\")"
      ],
      "metadata": {
        "id": "b5g29twSD5Qu",

        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "\n",

        "# ====== שלב 1: זיהוי חריגים עם Isolation Forest ======\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "yeshuv_grouped['Anomaly_ISO'] = iso_forest.fit_predict(\n",
        "    yeshuv_grouped[['YeshuvCrimeRateAvg', 'StationsNearbyAvg', 'CrimeTrendAvg']]\n",
        ")\n",
        "\n",
        "# סינון החריגים שנמצאו\n",
        "outliers_iso = yeshuv_grouped[yeshuv_grouped['Anomaly_ISO'] == -1]\n",
        "print(\"🔴 חריגים שזוהו על ידי Isolation Forest:\")\n",
        "print(outliers_iso)\n",
        "\n",
