{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [

      ]
    },
    {
      "cell_type": "code",

      "metadata": {
        "id": "-7mcT73id8cE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # 注 注 转 \n",
        "import matplotlib.pyplot as plt  # 爪转 专驻\n",

      ]
    },
    {
      "cell_type": "code",
      "source": [

        "\n",
        "# 专转 转 -GitHub\n",
        "!git clone https://github.com/orifelszer/CrimeData.git\n",
        "\n",
        "# 专转 转拽 专 专\n",
        "zip_folder = 'CrimeData'\n",
        "\n",
        "# 专转 转 砖专 砖 拽爪\n",
        "zip_files = [\n",
        "    os.path.join(zip_folder, 'Clean_data_unsupervised_part1.zip'),\n",
        "    os.path.join(zip_folder, 'Clean_data_unsupervised_part2.zip')\n",
        "]\n",
        "\n",
        "# 专砖 砖专转 转 拽爪 砖驻专住\n",
        "extracted_folders = []\n",
        "\n",
        "# 驻专住转 拽爪 -ZIP\n",
        "for zip_file in zip_files:\n",
        "    extract_path = zip_file.replace('.zip', '')  # 爪专转 砖 转拽 驻 砖 拽抓\n",
        "\n",
        "    # 拽  拽抓 拽\n",
        "    if os.path.exists(zip_file):\n",
        "        # 拽  转拽 专 驻专住\n",
        "        if not os.path.exists(extract_path):\n",
        "            with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "            print(f\"Extracted: {zip_file} -> {extract_path}\")\n",
        "        else:\n",
        "            print(f\"Skipped: {zip_file} (Already extracted)\")\n",
        "    else:\n",
        "        print(f\"File not found: {zip_file}\")\n",
        "\n",
        "    extracted_folders.append(extract_path)\n",
        "\n",
        "#  拽爪 CSV 砖驻专住\n",
        "dataframes = []\n",
        "\n",
        "for folder in extracted_folders:\n",
        "    for file_name in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, file_name)\n",
        "        if file_name.endswith('.csv'):\n",
        "            df_temp = pd.read_csv(file_path)\n",
        "            dataframes.append(df_temp)\n",
        "\n",
        "#   转 住专转 转 转\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 爪转 住专转 转 转\n",
        "print(f\"Combined dataset contains {combined_df.shape[0]} rows and {combined_df.shape[1]} columns.\")"
      ],
      "metadata": {
        "id": "b5g29twSD5Qu",

        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "\n",

        "# ====== 砖 1:  专 注 Isolation Forest ======\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "yeshuv_grouped['Anomaly_ISO'] = iso_forest.fit_predict(\n",
        "    yeshuv_grouped[['YeshuvCrimeRateAvg', 'StationsNearbyAvg', 'CrimeTrendAvg']]\n",
        ")\n",
        "\n",
        "# 住 专 砖爪\n",
        "outliers_iso = yeshuv_grouped[yeshuv_grouped['Anomaly_ISO'] == -1]\n",
        "print(\" 专 砖 注  Isolation Forest:\")\n",
        "print(outliers_iso)\n",
        "\n",
