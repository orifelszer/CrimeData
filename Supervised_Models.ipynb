{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orifelszer/CrimeData/blob/eden-branch/Supervised_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08868476-f47e-44ea-ae64-4905970e7172",
      "metadata": {
        "id": "08868476-f47e-44ea-ae64-4905970e7172"
      },
      "source": [
        "# Crimes Data in Israel (2019-2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99d3ace-5ef2-4b99-9025-d00c12fe818b",
      "metadata": {
        "id": "e99d3ace-5ef2-4b99-9025-d00c12fe818b"
      },
      "source": [
        "#### by: Eden Shmuel, Oriana Feltzer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642a9286-f6ea-4f53-834f-311bbf374fca",
      "metadata": {
        "id": "642a9286-f6ea-4f53-834f-311bbf374fca"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89aa6340-bd9e-4804-8cd9-c31b764cf0d4",
      "metadata": {
        "id": "89aa6340-bd9e-4804-8cd9-c31b764cf0d4"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9bcd36d6-c90e-480e-abcb-857b9d481c6b",
      "metadata": {
        "id": "9bcd36d6-c90e-480e-abcb-857b9d481c6b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ×”×•×¨×“×ª ×”×§×•×‘×¥ ×-GitHub\n",
        "!wget -O Data_Handling.py \"https://raw.githubusercontent.com/orifelszer/CrimeData/main/Data_Handling.py\"\n",
        "\n",
        "# ×™×™×‘×•× ×”×¤×•× ×§×¦×™×” ××”×§×•×‘×¥\n",
        "from Data_Handling import Preprocessing"
      ],
      "metadata": {
        "id": "D274npey667L",
        "outputId": "722d238a-83a6-4261-9b60-1d024b10b582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "D274npey667L",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-05 16:14:45--  https://raw.githubusercontent.com/orifelszer/CrimeData/main/Data_Handling.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5256 (5.1K) [text/plain]\n",
            "Saving to: â€˜Data_Handling.pyâ€™\n",
            "\n",
            "Data_Handling.py    100%[===================>]   5.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-05 16:14:45 (50.5 MB/s) - â€˜Data_Handling.pyâ€™ saved [5256/5256]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0278a92a-0025-49f5-8477-ab9a233c192a",
      "metadata": {
        "id": "0278a92a-0025-49f5-8477-ab9a233c192a"
      },
      "source": [
        "Define Paths to Crime Datasets (2019â€“2024)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/orifelszer/CrimeData.git\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_folder = 'CrimeData'\n",
        "\n",
        "zip_files = [f for f in os.listdir(zip_folder) if f.endswith('.zip')]\n",
        "\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(zip_folder, zip_file)\n",
        "    extract_path = os.path.join(zip_folder, zip_file.replace('.zip', ''))\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Extracted: {zip_file} -> {extract_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnDbNHN5cdsH",
        "outputId": "a5746789-a7ca-44ca-b349-1d03226140b3"
      },
      "id": "AnDbNHN5cdsH",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CrimeData'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 106 (delta 27), reused 13 (delta 13), pack-reused 68 (from 1)\u001b[K\n",
            "Receiving objects: 100% (106/106), 97.29 MiB | 12.38 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Extracted: crimes2024.zip -> CrimeData/crimes2024\n",
            "Extracted: crimes2019.zip -> CrimeData/crimes2019\n",
            "Extracted: crimes2020.zip -> CrimeData/crimes2020\n",
            "Extracted: crimes2023.zip -> CrimeData/crimes2023\n",
            "Extracted: crimes2021.zip -> CrimeData/crimes2021\n",
            "Extracted: crimes2022.zip -> CrimeData/crimes2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = glob.glob(\"CrimeData/**/*.csv\", recursive=True)\n",
        "dataframes = {f\"Crimes_{file[-8:-4]}\": pd.read_csv(file) for file in csv_files}"
      ],
      "metadata": {
        "id": "M76wikRj6YPT"
      },
      "id": "M76wikRj6YPT",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "20202bc4-abd9-457c-8b78-19acccf75f44",
      "metadata": {
        "id": "20202bc4-abd9-457c-8b78-19acccf75f44"
      },
      "source": [
        "Load Crime Data into Pandas DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f919ee99-df48-4632-821e-369f167355d3",
      "metadata": {
        "id": "f919ee99-df48-4632-821e-369f167355d3"
      },
      "source": [
        "Preview 2019 Crime Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dcc8d711-fcf8-4466-94cf-824136e6c507",
      "metadata": {
        "id": "dcc8d711-fcf8-4466-94cf-824136e6c507"
      },
      "outputs": [],
      "source": [
        "combined_data = pd.concat(dataframes, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ×”×¡×¨×ª ×©×•×¨×•×ª ×¢× ×¢×¨×š -1 ×‘×¢××•×“×ª StatisticGroupKod\n",
        "combined_data = combined_data[combined_data['StatisticGroupKod'] != -1]"
      ],
      "metadata": {
        "id": "CX4WQw1h4DXX"
      },
      "id": "CX4WQw1h4DXX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d0e074f6-c9cf-44ed-b887-a429c2ad1be6",
      "metadata": {
        "id": "d0e074f6-c9cf-44ed-b887-a429c2ad1be6"
      },
      "source": [
        "×‘×“×™×§×ª ×—×¨×™×’×™× ×œ×¤× ×™ ×—×œ×•×§×” ×œ××™××•×Ÿ ×•××‘×—×Ÿ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "079dce75-a400-4222-a927-5439392a6b36",
      "metadata": {
        "id": "079dce75-a400-4222-a927-5439392a6b36"
      },
      "outputs": [],
      "source": [
        "# ×©××™×¨×ª ×¢××•×“×•×ª ×”×—×™×–×•×™\n",
        "statistic_group = combined_data['StatisticGroup']\n",
        "statistic_group_kod = combined_data['StatisticGroupKod']\n",
        "\n",
        "# ×”×¡×¨×ª ×¢××•×“×•×ª ×”×—×™×–×•×™ ××”× ×ª×•× ×™×\n",
        "features = combined_data.drop(['StatisticGroup', 'StatisticGroupKod'], axis=1)\n",
        "\n",
        "# ×—×œ×•×§×” ×œ×¡×˜ ××™××•×Ÿ ×•×‘×“×™×§×”\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features,\n",
        "    statistic_group,  # ××©×ª××©×™× ×¨×§ ×‘-StatisticGroupKod ×›×¢××•×“×ª ×—×™×–×•×™\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=statistic_group  # ×©×•××¨ ×¢×œ ×”×ª×¤×œ×’×•×ª ×”×§×˜×’×•×¨×™×•×ª\n",
        ")\n",
        "\n",
        "# ×©××™×¨×ª ×¢××•×“×ª StatisticGroup (×œ×©×™××•×© ××¤×©×¨×™ ×‘×¢×ª×™×“)\n",
        "y_train_text = statistic_group_kod.loc[X_train.index]\n",
        "y_test_text = statistic_group_kod.loc[X_test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6b4c5e70-5bca-4df8-a4ec-c5b04db43bbb",
      "metadata": {
        "id": "6b4c5e70-5bca-4df8-a4ec-c5b04db43bbb"
      },
      "outputs": [],
      "source": [
        "# × ×™×§×•×™ ×¡×˜ ×”××™××•×Ÿ ×•×™×¦×™×¨×ª ××™×¤×•×™×™×\n",
        "X_train_cleaned, train_mappings, scaler = Preprocessing(X_train, fit_scaler=True)\n",
        "\n",
        "# × ×™×§×•×™ ×¡×˜ ×”×‘×“×™×§×” ×ª×•×š ×©×™××•×© ×‘××™×¤×•×™×™× ×©× ×•×¦×¨×• ×‘×¡×˜ ×”××™××•×Ÿ\n",
        "X_test_cleaned, _, _ = Preprocessing(X_test, train_mappings=train_mappings, scaler=scaler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ×”×’×“×¨×ª ×¢××•×“×•×ª ×œ×©××™×¨×” ×¢×œ ×‘×¡×™×¡ ×¡×˜ ×”××™××•×Ÿ ×‘×œ×‘×“\n",
        "columns_to_keep = [col for col in X_train_cleaned.columns if X_train_cleaned[col].sum() >= 10]\n",
        "\n",
        "# ×©××™×¨×” ×¢×œ ×¢××•×“×•×ª ××™××•×Ÿ ×¨×œ×•×•× ×˜×™×•×ª ×‘×œ×‘×“\n",
        "X_train_cleaned = X_train_cleaned[columns_to_keep]\n",
        "\n",
        "# ×”×ª×××ª ×¡×˜ ×”××‘×—×Ÿ ×¨×§ ×œ×¤×™ ××” ×©× ×§×‘×¢ ×‘××™××•×Ÿ\n",
        "for col in columns_to_keep:\n",
        "    if col not in X_test_cleaned.columns:\n",
        "        X_test_cleaned[col] = 0\n",
        "\n",
        "# ×”×‘×˜×—×” ×©×©× ×™ ×”×¡×˜×™× ×‘××•×ª×• ×¡×“×¨ ×¢××•×“×•×ª\n",
        "X_test_cleaned = X_test_cleaned[X_train_cleaned.columns]"
      ],
      "metadata": {
        "id": "Fa_GyJpNr5u1"
      },
      "id": "Fa_GyJpNr5u1",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "17ee9fa9-0444-4024-b1f6-392f84a378fc",
      "metadata": {
        "id": "17ee9fa9-0444-4024-b1f6-392f84a378fc"
      },
      "outputs": [],
      "source": [
        "# × ×ª×•× ×™× ×œ×¢×‘×•×“×”\n",
        "X_train = X_train_cleaned\n",
        "X_test = X_test_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ×”×ª×××ª ××™× ×“×§×¡×™×\n",
        "y_train = y_train.loc[X_train_cleaned.index]\n",
        "y_test = y_test.loc[X_test_cleaned.index]"
      ],
      "metadata": {
        "id": "hYrqLRmNiFkC"
      },
      "id": "hYrqLRmNiFkC",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models"
      ],
      "metadata": {
        "id": "dkyzukAlR0b1"
      },
      "id": "dkyzukAlR0b1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducing memory usage\n",
        "def optimize_data_types(df):\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        # ×× ××“×•×‘×¨ ×‘××©×ª× ×” ×§×˜×’×•×¨×™××œ×™ ×˜×§×¡×˜×•××œ×™\n",
        "        if col_type == 'object':\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "        # ×× ××“×•×‘×¨ ×‘××©×ª× ×” ××¡×¤×¨×™ ×¨×¦×™×£\n",
        "        elif col_type == 'float64':\n",
        "            df[col] = df[col].astype('float32')\n",
        "\n",
        "        # ×× ××“×•×‘×¨ ×‘××©×ª× ×” ××¡×¤×¨×™ ×©×œ×\n",
        "        elif col_type == 'int64':\n",
        "            df[col] = df[col].astype('int32')\n",
        "    return df\n",
        "\n",
        "# ×”×—×œ×ª ×”×¤×•× ×§×¦×™×” ×¢×œ ×¡×˜ ×”× ×ª×•× ×™×\n",
        "X_train = optimize_data_types(X_train)\n",
        "X_test = optimize_data_types(X_test)\n"
      ],
      "metadata": {
        "id": "GlDW7Q-BUZ5C"
      },
      "id": "GlDW7Q-BUZ5C",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ×™×™×‘×•× ×”×¡×¤×¨×™×•×ª ×”×“×¨×•×©×•×ª\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from itertools import product\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "Y26X_AAnR8N5"
      },
      "id": "Y26X_AAnR8N5",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ×“×’×™××” ×©×œ ×—×œ×§ ××¡×˜ ×”××™××•×Ÿ ×‘×œ×‘×“\n",
        "# X_train_sample = X_train.sample(frac=0.05, random_state=42)\n",
        "# y_train_sample = y_train.loc[X_train_sample.index]\n",
        "\n",
        "# # ×‘×—×™×¨×ª ×”×ª×›×•× ×•×ª ×¢×œ ×¡××š ×”×“×’×™××” ×‘×œ×‘×“\n",
        "# selector = SelectKBest(score_func=chi2, k=20)\n",
        "# selector.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "# # ×”×—×œ×ª ×”×‘×—×™×¨×” ×¢×œ ×›×œ ×¡×˜ ×”××™××•×Ÿ ×•×”×‘×“×™×§×”\n",
        "# X_train_selected = selector.transform(X_train)\n",
        "# X_test_selected = selector.transform(X_test)"
      ],
      "metadata": {
        "id": "kKM1kM1yUjx2"
      },
      "id": "kKM1kM1yUjx2",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ğŸ“ˆ ××•×“×œ ×‘×¡×™×¡×™ ×œ×œ× ×©×™×¤×•×¨×™× (Baseline)\n",
        "# sgd_model = SGDClassifier(loss='log_loss', class_weight='balanced', max_iter=100, random_state=42)\n",
        "# sgd_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# # ğŸ“Š ×—×™×–×•×™ ×¢×œ ×¡×˜ ×”×‘×“×™×§×”\n",
        "# y_pred_baseline = sgd_model.predict(X_test_selected)\n",
        "\n",
        "# # âœ… ×”×¢×¨×›×ª ×‘×™×¦×•×¢×™ ×”××•×“×œ\n",
        "# accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
        "# print(f\"Baseline Test Accuracy: {accuracy_baseline:.4f}\")"
      ],
      "metadata": {
        "id": "REniKuH_lpc9"
      },
      "id": "REniKuH_lpc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ğŸ” ×§×¨×•×¡-×•×œ×™×“×¦×™×” ×¢×œ ×”××•×“×œ ×”×‘×¡×™×¡×™\n",
        "# cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "# cv_scores = cross_val_score(sgd_model, X_train_selected, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "# # ×ª×•×¦××•×ª\n",
        "# print(f\"Cross-Validation Scores: {cv_scores}\")\n",
        "# print(f\"Average Accuracy: {np.mean(cv_scores):.4f}\")"
      ],
      "metadata": {
        "id": "5j1lV6ygls3Z"
      },
      "id": "5j1lV6ygls3Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š ×¤×•× ×§×¦×™×” ×œ××¦×™××ª ×”×¤×¨××˜×¨×™× ×”××•×¤×˜×™××œ×™×™× ×©×œ SGDClassifier\n",
        "def find_best_sgd_combination(X_train, y_train, X_test, y_test, alphas, max_iters, tols, k_features, cv_folds=3):\n",
        "    best_score = 0\n",
        "    best_params = {}\n",
        "    results = []\n",
        "\n",
        "    # ×œ×•×œ××” ×¢×œ ×›×œ ×”×§×•××‘×™× ×¦×™×•×ª ×”××¤×©×¨×™×•×ª\n",
        "    for alpha, max_iter, tol, k in product(alphas, max_iters, tols, k_features):\n",
        "\n",
        "        # ğŸ§© ×‘×—×™×¨×ª ×”×ª×›×•× ×•×ª\n",
        "        selector = SelectKBest(score_func=chi2, k=k)\n",
        "        selector.fit(X_train, y_train)\n",
        "        X_train_selected = selector.transform(X_train)\n",
        "        X_test_selected = selector.transform(X_test)\n",
        "\n",
        "        # ğŸ“ˆ ×‘× ×™×™×ª ××•×“×œ SGD ×¢× ×”×¤×¨××˜×¨×™× ×©× ×‘×“×§×™×\n",
        "        model = SGDClassifier(\n",
        "            loss='log_loss',\n",
        "            alpha=alpha,\n",
        "            max_iter=max_iter,\n",
        "            tol=tol,\n",
        "            random_state=42,\n",
        "            class_weight='balanced'\n",
        "        )\n",
        "\n",
        "        # ğŸ” ×§×¨×•×¡-×•×œ×™×“×¦×™×”\n",
        "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "        cv_scores = cross_val_score(model, X_train_selected, y_train, cv=cv, scoring='f1_macro')\n",
        "\n",
        "        # ××™××•×Ÿ ×”××•×“×œ ×¢×œ ×›×œ ×”×“××˜×”\n",
        "        model.fit(X_train_selected, y_train)\n",
        "        y_pred = model.predict(X_test_selected)\n",
        "\n",
        "        # ğŸ“Š ×—×™×©×•×‘ ××“×“×™×\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='macro')\n",
        "        recall = recall_score(y_test, y_pred, average='macro')\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "        # ×©××™×¨×ª ×”×ª×•×¦××•×ª ×‘×›×œ ×”×¨×¦×”\n",
        "        results.append({\n",
        "            'alpha': alpha,\n",
        "            'max_iter': max_iter,\n",
        "            'tol': tol,\n",
        "            'features': k,\n",
        "            'cv_f1_score': np.mean(cv_scores),\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "\n",
        "        # ×‘×“×™×§×” ×× ×”×ª×•×¦××” ×”× ×•×›×—×™×ª ×”×™× ×”×˜×•×‘×” ×‘×™×•×ª×¨\n",
        "        if f1 > best_score:\n",
        "            best_score = f1\n",
        "            best_params = {\n",
        "                'alpha': alpha,\n",
        "                'max_iter': max_iter,\n",
        "                'tol': tol,\n",
        "                'features': k,\n",
        "                'f1': f1\n",
        "            }\n",
        "\n",
        "    #×”×“×¤×¡×ª ×”×ª×•×¦××” ×”×˜×•×‘×” ×‘×™×•×ª×¨\n",
        "    print(f\"\\nğŸ“Š Best Parameters Found:\")\n",
        "    print(f\"Alpha: {best_params['alpha']}, Max Iter: {best_params['max_iter']}, Tol: {best_params['tol']}, Features: {best_params['features']}\")\n",
        "    print(f\"Best F1-Score: {best_params['f1']:.4f}\")\n",
        "\n",
        "    #×”×—×–×¨×ª ×›×œ ×”×ª×•×¦××•×ª ×•×”×¤×¨××˜×¨×™× ×”×˜×•×‘×™× ×‘×™×•×ª×¨\n",
        "    return results, best_params"
      ],
      "metadata": {
        "id": "eI8RWMyamZ-r"
      },
      "id": "eI8RWMyamZ-r",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ×“×•×’××” ×œ×¤×¨××˜×¨×™× ××¤×©×¨×™×™× ×œ×‘×“×™×§×”\n",
        "alphas = [0.0001, 0.001, 0.01]\n",
        "max_iters = [100, 300]\n",
        "tols = [1e-3, 1e-4]\n",
        "k_features = [10, 20]\n",
        "\n",
        "# ×§×¨×™××” ×œ×¤×•× ×§×¦×™×” ×¢× ×›×œ ×”×§×•××‘×™× ×¦×™×•×ª\n",
        "results, best_params = find_best_sgd_combination(X_train, y_train, X_test, y_test, alphas, max_iters, tols, k_features)\n",
        "\n",
        "# ×”×“×¤×¡×ª ×”×§×•××‘×™× ×¦×™×” ×”×˜×•×‘×” ×‘×™×•×ª×¨\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "X-JVpsEfm7V9",
        "outputId": "5358857c-0589-4973-c63f-17af1cdf98c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X-JVpsEfm7V9",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def find_best_random_forest_combination(X_train, y_train, X_test, y_test, n_estimators_list, max_depth_list, k_features, cv_folds=3):\n",
        "#     best_score = 0\n",
        "#     best_params = {}\n",
        "#     results = []\n",
        "\n",
        "#     # ×œ×•×œ××” ×¢×œ ×›×œ ×”×§×•××‘×™× ×¦×™×•×ª ×”××¤×©×¨×™×•×ª\n",
        "#     for n_estimators, max_depth, k in product(n_estimators_list, max_depth_list, k_features):\n",
        "\n",
        "#         # ğŸ§© ×‘×—×™×¨×ª ×”×ª×›×•× ×•×ª\n",
        "#         selector = SelectKBest(score_func=chi2, k=k)\n",
        "#         selector.fit(X_train, y_train)\n",
        "#         X_train_selected = selector.transform(X_train)\n",
        "#         X_test_selected = selector.transform(X_test)\n",
        "\n",
        "#         # ğŸ“ˆ ×‘× ×™×™×ª ××•×“×œ Random Forest ×¢× ×”×¤×¨××˜×¨×™× ×©× ×‘×“×§×™×\n",
        "#         model = RandomForestClassifier(\n",
        "#             n_estimators=n_estimators,\n",
        "#             max_depth=max_depth,\n",
        "#             random_state=42,\n",
        "#             class_weight='balanced')\n",
        "\n",
        "#         # ğŸ” ×§×¨×•×¡-×•×œ×™×“×¦×™×”\n",
        "#         cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "#         cv_scores = cross_val_score(model, X_train_selected, y_train, cv=cv, scoring='f1_macro')\n",
        "\n",
        "#         # ××™××•×Ÿ ×”××•×“×œ ×¢×œ ×›×œ ×”×“××˜×”\n",
        "#         model.fit(X_train_selected, y_train)\n",
        "#         y_pred = model.predict(X_test_selected)\n",
        "\n",
        "#         # ğŸ“Š ×—×™×©×•×‘ ××“×“×™×\n",
        "#         accuracy = accuracy_score(y_test, y_pred)\n",
        "#         precision = precision_score(y_test, y_pred, average='macro')\n",
        "#         recall = recall_score(y_test, y_pred, average='macro')\n",
        "#         f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "#         # ×©××™×¨×ª ×”×ª×•×¦××•×ª ×‘×›×œ ×”×¨×¦×”\n",
        "#         results.append({\n",
        "#             'n_estimators': n_estimators,\n",
        "#             'max_depth': max_depth,\n",
        "#             'features': k,\n",
        "#             'cv_f1_score': np.mean(cv_scores),\n",
        "#             'accuracy': accuracy,\n",
        "#             'precision': precision,\n",
        "#             'recall': recall,\n",
        "#             'f1': f1})\n",
        "\n",
        "#         # ×‘×“×™×§×” ×× ×”×ª×•×¦××” ×”× ×•×›×—×™×ª ×”×™× ×”×˜×•×‘×” ×‘×™×•×ª×¨\n",
        "#         if f1 > best_score:\n",
        "#             best_score = f1\n",
        "#             best_params = {\n",
        "#                 'n_estimators': n_estimators,\n",
        "#                 'max_depth': max_depth,\n",
        "#                 'features': k,\n",
        "#                 'f1': f1}\n",
        "\n",
        "#     # âœ… ×”×“×¤×¡×ª ×”×ª×•×¦××” ×”×˜×•×‘×” ×‘×™×•×ª×¨\n",
        "#     print(f\"\\nğŸ“Š Best Parameters Found:\")\n",
        "#     print(f\"N Estimators: {best_params['n_estimators']}, Max Depth: {best_params['max_depth']}, Features: {best_params['features']}\")\n",
        "#     print(f\"Best F1-Score: {best_params['f1']:.4f}\")\n",
        "\n",
        "#     # âœ… ×”×—×–×¨×ª ×›×œ ×”×ª×•×¦××•×ª ×•×”×¤×¨××˜×¨×™× ×”×˜×•×‘×™× ×‘×™×•×ª×¨\n",
        "#     return results, best_params"
      ],
      "metadata": {
        "id": "eBFHgRUxVK2d"
      },
      "id": "eBFHgRUxVK2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ×“×•×’××” ×œ×¤×¨××˜×¨×™× ××¤×©×¨×™×™× ×œ×‘×“×™×§×”\n",
        "# n_estimators_list = [50, 100, 200]\n",
        "# max_depth_list = [10, 15, 20]  # None ××©××¢ ×œ×œ× ×”×’×‘×œ×ª ×¢×•××§\n",
        "# k_features = [10, 20, 30]\n",
        "\n",
        "# # ×§×¨×™××” ×œ×¤×•× ×§×¦×™×” ×¢× ×›×œ ×”×§×•××‘×™× ×¦×™×•×ª\n",
        "# results, best_params = find_best_random_forest_combination(X_train, y_train, X_test, y_test, n_estimators_list, max_depth_list, k_features)\n",
        "\n",
        "# # ×”×“×¤×¡×ª ×”×§×•××‘×™× ×¦×™×” ×”×˜×•×‘×” ×‘×™×•×ª×¨\n",
        "# print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "B-__booJVzXF"
      },
      "id": "B-__booJVzXF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0f652a27-ea7c-4e67-9490-157bae3ae624",
      "metadata": {
        "id": "0f652a27-ea7c-4e67-9490-157bae3ae624"
      },
      "source": [
        "*****"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}