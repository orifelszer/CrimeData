{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orifelszer/CrimeData/blob/main/Supervised_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642a9286-f6ea-4f53-834f-311bbf374fca",
      "metadata": {
        "id": "642a9286-f6ea-4f53-834f-311bbf374fca"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Baseline Model (Dummy Classifier)\n",
        "Accuracy: 0.001\n",
        "Precision: 0.000001\n",
        "Recall: 0.001\n",
        "F1 Score: 0.000002\n",
        "Confusion Matrix: Mostly zeros, indicating poor performance.\n",
        "2. Decision Tree Classifier\n",
        "Accuracy: 0.043\n",
        "Precision: 0.279\n",
        "Recall: 0.043\n",
        "F1 Score: 0.048\n",
        "Confusion Matrix: Shows some correct predictions but overall poor performance.\n",
        "3. Deep Neural Network (DNN)\n",
        "Accuracy: 0.356\n",
        "Precision: 0.239\n",
        "Recall: 0.356\n",
        "F1 Score: 0.247\n",
        "Confusion Matrix: Indicates a better spread of correct predictions compared to the Decision Tree.\n",
        "4. Random Forest Classifier\n",
        "Accuracy: 0.048\n",
        "Precision: 0.300\n",
        "Recall: 0.048\n",
        "F1 Score: 0.070\n",
        "Confusion Matrix: Shows more correct predictions compared to the Decision Tree but still overall poor performance.\n",
        "5. LightGBM (LGBM)\n",
        "Accuracy: 0.116\n",
        "Precision: 0.302\n",
        "Recall: 0.116\n",
        "F1 Score: 0.137\n",
        "Confusion Matrix: Shows better performance than the Random Forest.\n",
        "6. XGBoost (XGB)\n",
        "Accuracy: 0.382\n",
        "Precision: 0.352\n",
        "Recall: 0.382\n",
        "F1 Score: 0.314\n",
        "Confusion Matrix: Shows the best performance among all models.\n",
        "Interpretation and Comparison\n",
        "Baseline Model:\n",
        "\n",
        "The Dummy Classifier performs very poorly with almost zero accuracy, precision, recall, and F1 score. It serves as a basic benchmark.\n",
        "Decision Tree Classifier:\n",
        "\n",
        "Slightly better than the baseline but still performs poorly with low accuracy and F1 score. It struggles with the complexity of the data.\n",
        "Deep Neural Network (DNN):\n",
        "\n",
        "Significantly better than the Decision Tree with an accuracy of 35.6%. The DNN shows improved recall and F1 score, indicating a better balance between precision and recall.\n",
        "Random Forest Classifier:\n",
        "\n",
        "Slightly better than the Decision Tree but still performs poorly overall. The accuracy and F1 score are low, indicating the model struggles with the data complexity.\n",
        "LightGBM (LGBM):\n",
        "\n",
        "Shows an improvement over the Random Forest with an accuracy of 11.6%. The precision and F1 score are also better, indicating a more balanced performance.\n",
        "XGBoost (XGB):\n",
        "\n",
        "The best performing model with an accuracy of 38.2%. It also has the highest F1 score, indicating a good balance between precision and recall. The confusion matrix shows a better distribution of correct predictions.\n",
        "Conclusion\n",
        "Best Model: The XGBoost model outperforms all other models in terms of accuracy, precision, recall, and F1 score. It should be the preferred choice for this task.\n",
        "DNN Performance: The Deep Neural Network also performs well and could be considered as an alternative to XGBoost if further improvements are made.\n",
        "Tree-Based Models: The Decision Tree and Random Forest models perform poorly, indicating that they might not handle the complexity of the data well.\n",
        "LightGBM: While better than the Random Forest, LightGBM still lags behind the XGBoost and DNN models."
      ],
      "metadata": {
        "id": "nsx8Y7EzNFrF"
      },
      "id": "nsx8Y7EzNFrF"
    },
    {
      "cell_type": "markdown",
      "id": "0f652a27-ea7c-4e67-9490-157bae3ae624",
      "metadata": {
        "id": "0f652a27-ea7c-4e67-9490-157bae3ae624"
      },
      "source": [
        "*****"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the metrics for each model\n",
        "metrics = {\n",
        "    \"Baseline Model\": {\n",
        "        \"Accuracy\": 0.001,\n",
        "        \"Precision\": 0.000001,\n",
        "        \"Recall\": 0.001,\n",
        "        \"F1 Score\": 0.000002\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        \"Accuracy\": 0.043,\n",
        "        \"Precision\": 0.279,\n",
        "        \"Recall\": 0.043,\n",
        "        \"F1 Score\": 0.048\n",
        "    },\n",
        "    \"DNN\": {\n",
        "        \"Accuracy\": 0.356,\n",
        "        \"Precision\": 0.239,\n",
        "        \"Recall\": 0.356,\n",
        "        \"F1 Score\": 0.247\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"Accuracy\": 0.048,\n",
        "        \"Precision\": 0.300,\n",
        "        \"Recall\": 0.048,\n",
        "        \"F1 Score\": 0.070\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"Accuracy\": 0.116,\n",
        "        \"Precision\": 0.302,\n",
        "        \"Recall\": 0.116,\n",
        "        \"F1 Score\": 0.137\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"Accuracy\": 0.382,\n",
        "        \"Precision\": 0.352,\n",
        "        \"Recall\": 0.382,\n",
        "        \"F1 Score\": 0.314\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "P7pZxkbthkQD"
      },
      "id": "P7pZxkbthkQD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the metrics dictionary\n",
        "df_metrics = pd.DataFrame(metrics).T\n",
        "\n",
        "# Sort the DataFrame by the 'Accuracy' column in descending order\n",
        "df_metrics_sorted = df_metrics.sort_values(by='Accuracy', ascending=False)\n",
        "\n",
        "# Print the sorted comparison table\n",
        "print(df_metrics_sorted)\n",
        "\n",
        "# Optionally, save the sorted comparison table to a CSV file\n",
        "df_metrics_sorted.to_csv(\"sorted_model_comparison_table.csv\", index=True)"
      ],
      "metadata": {
        "id": "dJDOqAGfIwch",
        "outputId": "1073d7a6-6ec8-4b1e-ab3a-38ad2999a397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dJDOqAGfIwch",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Accuracy  Precision  Recall  F1 Score\n",
            "XGBoost            0.382   0.352000   0.382  0.314000\n",
            "DNN                0.356   0.239000   0.356  0.247000\n",
            "LightGBM           0.116   0.302000   0.116  0.137000\n",
            "Random Forest      0.048   0.300000   0.048  0.070000\n",
            "Decision Tree      0.043   0.279000   0.043  0.048000\n",
            "Baseline Model     0.001   0.000001   0.001  0.000002\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}